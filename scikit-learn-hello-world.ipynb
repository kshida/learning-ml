{"cells":[{"cell_type":"markdown","metadata":{"id":"yAkslIIAbppt"},"source":["# scikit-learnのサンプルデータセットを使って、簡単な機械学習をしてみよう！"]},{"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kshida/learning-ml/blob/main/scikit-learn-hello-world.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"4G8fVZtDZ2CV"},"source":["今回は機械学習界隈におけるHelloWorld的なアイリスデータセット（アヤメの種類のデータ）を使います。  \n","アヤメはがくの幅と長さ、花びらの幅と長さで種類が決まるため、データ分類の入門として扱いやすい存在のためです。"]},{"cell_type":"markdown","metadata":{"id":"6C90j9qVaB4A"},"source":["必要なデータはそれぞれ以下となります。\n","1. Sepal Length(cm) がくの長さ\n","2. Sepal Width がくの幅\n","3. Petal length 花びらの長さ\n","4. petal Width 花びらの幅\n","\n","\n","また、用意されている種別は3つです。\n","- [setosa（セトサ）](https://www.fs.fed.us/wildflowers/beauty/iris/Blue_Flag/iris_setosa.shtml)\n","- [versicolor（バージカラー）](https://www.fs.fed.us/wildflowers/beauty/iris/Blue_Flag/iris_versicolor.shtml)\n","- [virginica（バージニカ）](https://www.fs.fed.us/wildflowers/beauty/iris/Blue_Flag/iris_virginica.shtml) ※ 今回は使わない"]},{"cell_type":"markdown","metadata":{"id":"fe33v6aAdkfR"},"source":["## コードを書いていこう！"]},{"cell_type":"markdown","metadata":{"id":"_bltyT92fEZE"},"source":["### データの下準備"]},{"cell_type":"markdown","metadata":{"id":"2wVK577bb_M8"},"source":["まずは必要なパッケージとデータセットをインポートしましょう。"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":684,"status":"ok","timestamp":1646325745921,"user":{"displayName":"信太滉平","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11515365079994934035"},"user_tz":-540},"id":"LXCPmpYMaQB2"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import datasets\n","import random\n","\n","iris = datasets.load_iris()\n","iris_data = iris.data\n","sl_data = iris_data[:100, 0] # SetosaとVersicolorに関するSepal lengthのデータ\n","sw_data = iris_data[:100, 1] # SetosaとVersicolorに関するSepal widthのデータ"]},{"cell_type":"markdown","metadata":{"id":"VId-Mrrgd2IV"},"source":["機械学習をする上では、正負のデータのバランスが良い方が好ましいです。（学習させやすい）  \n","そのため、平均値を引いてあげてバランスを整えましょう。"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1646325748999,"user":{"displayName":"信太滉平","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11515365079994934035"},"user_tz":-540},"id":"GDUKAmN4eOVD"},"outputs":[],"source":["sl_ave = np.average(sl_data)  # 平均値を算出\n","sl_data -= sl_ave  # 平均値を引くことで平均値=0にする\n","sw_ave = np.average(sw_data)\n","sw_data -= sw_ave\n","\n","# 整えたデータをリストに格納する（これが学習用データとなる）\n","train_data = []\n","for i in range(100):\n","    correct = iris.target[i]\n","    train_data.append([sl_data[i], sw_data[i], correct])"]},{"cell_type":"markdown","metadata":{"id":"j7LIaxv_fK4z"},"source":["### ニューラルネットワークの作成"]},{"cell_type":"markdown","metadata":{"id":"0-cjeHN4e9js"},"source":["ニューロンの中にある**活性化関数**を用意します。  \n","活性化関数には[シグモイド関数](https://atmarkit.itmedia.co.jp/ait/articles/2003/04/news021.html)を使用します。  \n","詳細は割愛しますが、シグモイド関数は点対称となるS字型の滑らかな曲線を描く関数で、0~1の間の値を返します。  \n","そのため、2つに分類するタイプの計算に用いられやすい関数です。"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":272,"status":"ok","timestamp":1646325751770,"user":{"displayName":"信太滉平","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11515365079994934035"},"user_tz":-540},"id":"MlMSqDj-f_Hd"},"outputs":[],"source":["# シグモイド関数の公式\n","def sigmoid(x):\n","    return 1.0 / (1.0 + np.exp(-x))"]},{"cell_type":"markdown","metadata":{"id":"-mMfH_SzgYJE"},"source":["続いて、ニューロンを定義します。  \n","入力と出力ができるようにsetterとgetterを定義しましょう。"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":258,"status":"ok","timestamp":1646325753933,"user":{"displayName":"信太滉平","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11515365079994934035"},"user_tz":-540},"id":"6DdgmmOZgtR7"},"outputs":[],"source":["# ニューロン\n","class Neuron:\n","    def __init__(self):\n","        self.input_sum = 0.0\n","        self.output = 0.0\n","\n","    def set_input(self, inp):\n","        self.input_sum += inp\n","\n","    def get_output(self):\n","        self.output = sigmoid(self.input_sum)\n","        return self.output\n","\n","    def reset(self):\n","        self.input_sum = 0\n","        self.output = 0"]},{"cell_type":"markdown","metadata":{"id":"WStuuSS0g9Ph"},"source":["次はニューラルネットワークの構築です。  \n","今しがた定義したニューロンのインスタンスを生成し、入力層・中間層・出力層の3つを宣言しましょう。  "]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":383,"status":"ok","timestamp":1646325756901,"user":{"displayName":"信太滉平","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11515365079994934035"},"user_tz":-540},"id":"SLbtsLv-hMZO"},"outputs":[],"source":["# ニューラルネットワーク\n","class NeuralNetwork:\n","    def __init__(self):\n","        # 重み（固定）\n","        self.w_im = [[4.0, 4.0], [4.0, 4.0], [4.0, 4.0]]  # 入力は2つ ニューロンは3つ\n","        self.w_mo = [[1.0, -1.0, 1.0]]  # 入力は3つ ニューロンは1つ\n","\n","        # バイアス（固定）\n","        self.b_m = [3.0, 0.0, -3.0]  # ニューロンは3つ\n","        self.b_o = [-0.5]  # ニューロンは1つ\n","\n","        self.input_layer = [0.0, 0.0] # 入力層\n","        self.middle_layer = [Neuron(), Neuron(), Neuron()] # 中間層\n","        self.output_layer = [Neuron()] # 出力層\n","\n","    def commit(self, input_data):\n","        # 入力層にデータを渡す\n","        self.input_layer[0] = input_data[0]\n","        self.input_layer[1] = input_data[1]\n","        # 中間層と出力層を初期化\n","        self.middle_layer[0].reset()\n","        self.middle_layer[1].reset()\n","        self.middle_layer[2].reset()\n","        self.output_layer[0].reset()\n","\n","        # 入力層→中間層1つ目\n","        self.middle_layer[0].set_input(self.input_layer[0] * self.w_im[0][0])\n","        self.middle_layer[0].set_input(self.input_layer[1] * self.w_im[0][1])\n","        self.middle_layer[0].set_input(self.b_m[0])\n","\n","        # 入力層→中間層2つ目\n","        self.middle_layer[1].set_input(self.input_layer[0] * self.w_im[1][0])\n","        self.middle_layer[1].set_input(self.input_layer[1] * self.w_im[1][1])\n","        self.middle_layer[1].set_input(self.b_m[1])\n","\n","        # 入力層→中間層3つ目\n","        self.middle_layer[2].set_input(self.input_layer[0] * self.w_im[2][0])\n","        self.middle_layer[2].set_input(self.input_layer[1] * self.w_im[2][1])\n","        self.middle_layer[2].set_input(self.b_m[2])\n","\n","        # 中間層→出力層\n","        self.output_layer[0].set_input(self.middle_layer[0].get_output() * self.w_mo[0][0])\n","        self.output_layer[0].set_input(self.middle_layer[1].get_output() * self.w_mo[0][1])\n","        self.output_layer[0].set_input(self.middle_layer[2].get_output() * self.w_mo[0][2])\n","        self.output_layer[0].set_input(self.b_o[0])\n","\n","        return self.output_layer[0].get_output()\n","\n","    def train(self, correct):\n","        # 学習係数\n","        k = 0.3\n","\n","        #  出力\n","        output_o = self.output_layer[0].output\n","        output_m0 = self.middle_layer[0].output\n","        output_m1 = self.middle_layer[1].output\n","        output_m2 = self.middle_layer[2].output\n","\n","        # δ\n","        delta_o = (output_o - correct) * output_o * (1.0 - output_o)\n","        delta_m0 = delta_o * self.w_mo[0][0] * output_m0 * (1.0 - output_m0)\n","        delta_m1 = delta_o * self.w_mo[0][1] * output_m1 * (1.0 - output_m1)\n","        delta_m2 = delta_o * self.w_mo[0][2] * output_m2 * (1.0 - output_m2)\n","\n","        # パラメータの更新\n","        self.w_mo[0][0] -= k * delta_o * output_m0\n","        self.w_mo[0][1] -= k * delta_o * output_m1\n","        self.w_mo[0][2] -= k * delta_o * output_m2\n","        self.b_o[0] -= k * delta_o\n","\n","        self.w_im[0][0] -= k * delta_m0 * self.input_layer[0]\n","        self.w_im[0][1] -= k * delta_m0 * self.input_layer[1]\n","        self.w_im[1][0] -= k * delta_m1 * self.input_layer[0]\n","        self.w_im[1][1] -= k * delta_m1 * self.input_layer[1]\n","        self.w_im[2][0] -= k * delta_m2 * self.input_layer[0]\n","        self.w_im[2][1] -= k * delta_m2 * self.input_layer[1]\n","        self.b_m[0] -= k * delta_m0 \n","        self.b_m[1] -= k * delta_m1 \n","        self.b_m[2] -= k * delta_m2\n","\n","# ニューラルネットワークのインスタンスを生成する\n","neural_network = NeuralNetwork()"]},{"cell_type":"markdown","metadata":{"id":"Xg4557d2lu5m"},"source":["途中で出てきた「δ（デルタ）」は誤差逆伝播法を表します。  \n","正直微分とか出まくりで分かりにくいのですが、ざっくり説明しますと、  \n","出力層→中間層→入力層へと遡りつつ、本来出力されるべき値と実際の出力結果との誤差を見てパラメータを調整する方法のことです。  \n","（入力層から出力層まで学習させていくことは順伝播法と言います。）\n","\n","【余談】  \n","もともとニューラルネットワークは3層までが限界だったのですが、この逆伝播法が登場したことで学習効率が飛躍的に良くなり、3層を超えてニューラルネットワークを構築することができるようになりました。  \n","その結果ディープラーニングができるようになったので、実はすごいブレイクスルーなのです。"]},{"cell_type":"markdown","metadata":{"id":"GflxoGR7mRrW"},"source":["### 学習結果の可視化"]},{"cell_type":"markdown","metadata":{"id":"-w2EUb7wmetF"},"source":["ここまで来たらあと少しです。  \n","学習結果を見やすくするための関数を用意しましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1646325763592,"user":{"displayName":"信太滉平","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11515365079994934035"},"user_tz":-540},"id":"kJwOiuY5mcWW","outputId":"67918509-cb22-4d98-d33e-97d9f9494890"},"outputs":[],"source":["def show_graph(epoch):\n","    print(\"Epoch:\", epoch)\n","\n","    st_predicted = [[], []]  # Setosaに分類されるもの\n","    vc_predicted = [[], []]  # Versicolorに分類されるもの\n","    for data in train_data:\n","        if neural_network.commit(data) < 0.5:\n","            st_predicted[0].append(data[0]+sl_ave)\n","            st_predicted[1].append(data[1]+sw_ave)\n","        else:\n","            vc_predicted[0].append(data[0]+sl_ave)\n","            vc_predicted[1].append(data[1]+sw_ave)\n","\n","    # 分類結果をグラフで表示する\n","    plt.scatter(st_predicted[0], st_predicted[1], label=\"Setosa\")\n","    plt.scatter(vc_predicted[0], vc_predicted[1], label=\"Versicolor\")\n","    plt.legend()\n","\n","    plt.xlabel(\"Sepal length (cm)\")\n","    plt.ylabel(\"Sepal width (cm)\")\n","    plt.show()\n","\n","# グラフで表示\n","show_graph(0)"]},{"cell_type":"markdown","metadata":{"id":"P1e14H_Hm-aS"},"source":["さて、それではデータを学習させてみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1752,"status":"ok","timestamp":1646325772510,"user":{"displayName":"信太滉平","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11515365079994934035"},"user_tz":-540},"id":"mVR8KKFZnIBR","outputId":"eca58428-476e-467d-c9a9-1adaf20b4c8d"},"outputs":[],"source":["for t in range(0, 64):\n","    random.shuffle(train_data)\n","    for data in train_data:\n","        neural_network.commit(data[:2])  # 順伝播\n","        neural_network.train(data[2])  # 逆伝播\n","    # 一定回数学習するごとにグラフで表示する\n","    if t+1 in [1, 2, 4, 8, 16, 32, 64]:\n","        show_graph(t+1)"]},{"cell_type":"markdown","metadata":{"id":"JVnXGKLVntHH"},"source":["せっかくなので、比較用にもとの正しい状態の分類も表示してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1646325801287,"user":{"displayName":"信太滉平","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11515365079994934035"},"user_tz":-540},"id":"ED7_3TRZnx40","outputId":"38f6d0ea-0594-4e8d-efdd-ece265c7ad76"},"outputs":[],"source":["st_data = iris_data[:50]  # Setosaのデータ\n","vc_data = iris_data[50:100]  # Versicolorのデータ\n","plt.scatter(st_data[:, 0], st_data[:, 1], label=\"Setosa\")\n","plt.scatter(vc_data[:, 0], vc_data[:, 1], label=\"Versicolor\")\n","plt.legend()\n","\n","plt.xlabel(\"Sepal length (cm)\")\n","plt.ylabel(\"Sepal width (cm)\")\n","plt.title(\"Original\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"dDKmZ8dhoEGw"},"source":["## 終わりに"]},{"cell_type":"markdown","metadata":{"id":"9XgOeZfDoG3k"},"source":["これが基本的な機械学習の流れになります！  \n","実用的な学習をさせるためには数百~数億のパラメータが必要になるため、学習には手間も時間もかかります。  \n","そもそもの学習モデルが正しいかどうかも分からないので、地道に学習を繰り返していくか、知見の豊富な方にご助力いただくかしないと厳しいかもしれません。  \n","\n","ですが、身の回りのちょっとした学習程度であれば、今回のように触って楽しみながら学んでいくことができると思います。  \n","このノートブックが機械学習入門へのきっかけになれば嬉しいです！"]},{"cell_type":"markdown","metadata":{"id":"kO3M0cV7pXIz"},"source":["### 謝辞"]},{"cell_type":"markdown","metadata":{"id":"exZauLGwpY-Q"},"source":["このnotebookは「[みんなのAI講座 ゼロからPythonで学ぶ人工知能と機械学習](https://github.com/yukinaga/minnano_ai)」を参考に、社内LT用に調整したものになります。  \n","我妻先生のUdemyの講座はとても分かりやすく、機械学習の楽しさに気づくことができました。  \n","素晴らしい講座をありがとうございます。"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO2o8sb6aKo2zUPSBLPOLFO","name":"scikit-learn-hello-world.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
