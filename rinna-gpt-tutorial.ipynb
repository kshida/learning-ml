{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kshida/learning-ml/blob/main/rinna-gpt-tutorial.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"13QmVm4Kw2BA"},"source":["# 自然言語処理に触れてみよう！"]},{"cell_type":"markdown","metadata":{"id":"DXhgklg8w7ER"},"source":["自然言語処理用のライブラリをインストールします。  \n","- [Transformers](https://github.com/huggingface/transformers)：アメリカのHugging Face社が提供している自然言語処理用のライブラリ。Hugging Faceは[機械学習用のサイト](https://huggingface.co/)も公開している（日本語はないけれど・・）\n","- [Sentencepiece](https://github.com/google/sentencepiece)：Google先生作成の言語をセンテンスごとに分割してくれるトークナイザ。形態素解析に比べて、遥かに少ない語彙数で学習できる"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LIOvzsHs4UKY"},"outputs":[],"source":["!pip install transformers\n","!pip install sentencepiece"]},{"cell_type":"markdown","metadata":{"id":"PGlaEXSmyOI3"},"source":["続いて、rinna社が[先日提供開始](https://rinna.co.jp/%E3%83%8B%E3%83%A5%E3%83%BC%E3%82%B9/f/%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%81%AB%E7%89%B9%E5%8C%96%E3%81%97%E3%81%9F13%E5%84%84%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%81%AEgpt%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E5%85%AC%E9%96%8B)した日本語GPTモデルを読み込みます。  \n","※ GPTは、単語の確率の組み合わせから次の単語の確率を計算する言語モデルのこと。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LUyD3Pfr4MWt"},"outputs":[],"source":["import torch\n","from transformers import T5Tokenizer, AutoModelForCausalLM\n","\n","# トークナイザとモデル本体を読み込む\n","tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt-1b\")\n","model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt-1b\")\n","\n","# GPU使用時の設定\n","if torch.cuda.is_available():\n","    model = model.to(\"cuda\")"]},{"cell_type":"markdown","metadata":{"id":"4DCH483_zMB7"},"source":["それでは文章を生成してみましょう！"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8-CAILP6nvz"},"outputs":[],"source":["# 入力文（任意の言葉を入れる）\n","text = \"1on1で重要なことは\"\n","\n","# 入力文のトークナイズ\n","token_ids = tokenizer.encode(text, add_special_tokens=False, return_tensors=\"pt\")\n","\n","# 入力文とパラメータの設定にしたがって文章を生成\n","with torch.no_grad():\n","    output_ids = model.generate(\n","        token_ids.to(model.device),\n","        max_length=100,\n","        min_length=100,\n","        do_sample=True,\n","        top_k=500,\n","        top_p=0.95,\n","        pad_token_id=tokenizer.pad_token_id,\n","        bos_token_id=tokenizer.bos_token_id,\n","        eos_token_id=tokenizer.eos_token_id,\n","        bad_word_ids=[[tokenizer.unk_token_id]]\n","    )\n","\n","# 生成された文章を単語IDから実際の単語に変換\n","output = tokenizer.decode(output_ids.tolist()[0])\n","print(output)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOyCe2sSWDMpmAAMpmmvGtw","name":"rinna-gpt-tutorial.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
